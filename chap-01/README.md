# 01. 쿠버네티스 소개


* 많은 애플리케이션이 하나의 프로세스 또는 몇개의 서버에 분산된 프로세스로 실행되며 릴리스 주기가 느린 **모놀리스**에서 독립적으로 개발 및 배포되며 자주 업데이트가 가능한 **마이크로서비스**로 변화
* 구성요소의 수가 많아지면서 이를 구성 및 관리하는 일이 점점 어려워짐
* 쿠버네티스가 이를 대신 해줌
* 개발팀은 운영팀 없이 쉽게 자주 배포 및 운영 가능
* 개발팀 뿐만 아니라 운영팀도 애플리케이션 자체가 아니라 인프라를 감독하는 것에 집중할 수 있게 해줌
* 애플리케이션은 쿠버네티스가 관리해줌
* 클러스터를 하나의 거대한 컴퓨팅 리소스로 추상화
* 리소스를 활용률을 높이고 하드웨어 비용을 낮춰줌

## 1.1 쿠버네티스와 같은 시스템이 필요한 이유 
* 모놀리스의 단점
  * 일부를 변경하더라도 전체를 재배포해야함
  * 컴포넌트간의 경계가 불분명해지고 결합도가 커져 복잡도 증가
  * 확장이 어려움
    * 수직 확장은 한계가 있고 비용이 비쌈
    * 수평 확장을 하려면 전체 시스템을 복사해야하는데, 일부분이 확장되기 어려울 수 있음(RDB)
* 마이크로서비스의 특징 및 장점
  * 잘 정의된 인터페이스(API)로 컴포넌트간 통신
  * 컴포넌트간 통신 방식
    * 동기 프로토콜(HTTP)
    * 비동기 프로토콜(AMQP)
    * gRPC, RSocket, ...
  * 각 컴포넌트는 서로 다른 언어로 구현 가능
  * 개별적으로 개발 및 배포 가능
  * 개별적으로 확장 가능
  * 자유롭게 서로 다른 서버에서 실행 가능
* 마이크로서비스의 단점
  * 컴포넌트의 수가 너무 많아져서 구성 및 운영, 장애 시 대처가 어려움
  * 디버깅이 어려움
  * 종속성 관리 어려움
    * 환경 요구사항의 다양성
    * 동일한 서버에서 여러 앱이 실행되면 다른 버전의 동일한 라이브러리의 사용으로 인한 충돌 발생 가능
* 데브옵스
  * 과거에는 개발자가 애플리케이션을 만들어서 운영팀에 넘겨주었다
  * 이제는 개발팀이 배포와 관리를 모두 하는것이 낫다는 것을 꺠달았다
  * 개발자, QA, 운영팀이 전체 프로세스에서 협업하는 것
* 데브옵스 장점
  * 자주 배포하여 추가적인 사용자의 피드백을 받아 반영하기 수월
* 개발팀과 운영팀의 관심사 차이
  * 개발팀은 새로운 기능의 추가, 사용자 경험의 향상에 관심
  * 운영팀은 보안, 사용률, 인프라 유지 등, 개발팀과는 다른 측면에 관심
  * **쿠버네티스는 개발팀과 운영팀이 각자의 관심사에 집중할 수 있게 해줌**
* 노옵스
  * 하드웨어 인프라를 전혀 알지 못하더라도 운영 팀을 거치지 않고 개발자가 애플리케이션을 직접 배포하는 방식
  
## 1.2 컨테이너 기술 소개
* 가상머신과 컨테이너
  * 서로 다른 환경에서 실행되는 여러 구성요소들을 위해 여러 VM을 사용할 수 있음
  * 하지만 구성요소의 크기가 점점 작아지고, 수가 많아지면 각 구성요소를 가상머신으로 구성하면 리소스의 낭비와 관리자의 작업량이 증가
  * VM 대신 리눅스 컨테이너 기술 사용
  * VM 과는 달리 동일한 컨테이너에서 실행되는 프로세스는 모두 동일한 호스트에서 실행
  * VM 은 컴포넌트 프로세스 이외에 시스템 프로세스도 실행해야 하므로 추가 리소스가 필요
  * 컨테이너는 단지 격리된 프로세스
  * VM 에서 시스템콜을 수행하면 게스트OS -> 하이퍼바이저 -> 호스트OS 로 전달 
* 컨테이너의 격리 메커니즘
  * namespace
    * 각 프로세스가 시스템(파일, 프로세스, 네트워크 인터페이스, 호스트 이름 등)에 대한 독립된 뷰만 볼 수 있도록 함
  * cgroup
    * 리눅스 컨트롤 그룹으로, 프로세스가 사용할 수 있는 리소스(CPU, 메모리, 네트워크 대역폭 등)의 양을 제한
  * 각 컨테이너는 고유한 네트워크 인터페이스를 가짐
* 도커
  * VM 에서 동일한 파일 시스템(, 바이너리, 라이브러리, 즉 게스트 OS 커널)에서 실행되는 앱들이 같은 파일을 공유할 수 있는것은 당연
  * Docker 는 Layer 라는 개념을 사용하여 같은 파일을 같은 Layer 로 공유
  * 하지만 Layer 는 읽기 전용이라 한 컨테이너가 파일을 수정한 것을 다른 컨테이너는 보지 못함
    * 컨테이너가 실행될 때 마지막에 쓰기 가능한 Layer 하나를 쌓음
    * 파일을 수정하면 전체 파일의 복사본이 쓰기 가능한 최상위 Layer 에 만들어지고 그곳을 수정
  * 한계
    * 커널(호스트 OS)을 공유하기 때문에, 컨테이너화 된 애플리케이션이 특정 커널 버전을 필요로 하는 경우 작동 안 할 수도
      * VM 은 자체 커널을 실행하기 때문에 이런 제약 없음
    * x86 아키텍처용 애플리케이션을 ARM 기반 컴퓨터에서 실행 불가능
      * VM 은 가능 
  * Docker 가 K8s 의 Kubelet 에서 지원하는 유일한 CRI(Container Runtime Interface)는 아님
    * [참고](https://kubernetes.io/docs/setup/production-environment/container-runtimes/)
    * K8s 는 단순히 컨테이너 오케스트레이션 시스템이 아니라 그 이상임
  
## 1.3 쿠버네티스 소개
* 쿠버네티스의 기원
  * 구글에서 내부 시스템 Borg -> Omega 를 기반으로 2014년에 오픈 소스로 출시
* 넓은 시각으로 바라보기
  * 쿠버네티스는 컨테이너화된 애플리케이션을 배포하고 관리하도록 도와주는 시스템
  * 한정된 하드웨어 자원을 여러 조직에서 사용할 수 있게 하여 최대한으로 활용 
  * 쿠버네티스를 통해 클러스터는 하나의 컴퓨터 처럼 추상화되어 개발, 배포, 관리를 단순화
  * 쿠버네티스 핵심 이해
    * 시스템은 워커 노드와 마스터 노드로 구분되며, 개발자가 마스터에 애플리케이션 매니페스트를 배포하면, 마스터는 이를 워커 노드에 자동으로 배포한다.
  * 개발자가 애플리케이션 핵심 기능에 집중할 수 있도록 지원
    * 쿠버네티스는 마치 클러스터 전체의 OS와도 같이 다양한 기능을 지원하며, 개발자는 애플리케이션 기능 개발에만 집중하면 된다.
  * 운영 팀이 효과적으로 리소스를 활용할 수 있도록 지원
    * 구성 요소간 서비스 디스커버리를 기반으로 애플리케이션이 실행되는 노드의 위치는 상관이 없기에, 애플리케이션의 배치, 조합이 훨씬 자유롭다.
* 쿠버네티스 클러스터 아키텍쳐 이해
  * 하드웨어 개요
    * 마스터 노드 - 컨트롤  플레인 실행
    * 워커 노드 - 실제 배포되는 컨테이너 애플리케이션 실행
  * 마스터 노드 - 컨트롤 플레인(Control Plane) 구성요소
    * k8s API 서버 - 사용자, 컨트롤 플레인 구성 요서와 통신
    * 스케줄러 - 애플리케이션 배포
    * 컨트롤러 매니저 - 구성 요소 복제본, 워커 노드 추적, 노드 장애 처리 등과 같은 클러스터 기능
    * Etcd는 클러스터 구성을 지속적으로 저장하는 신뢰성 있는 분산 데이터 저장소
  * 워커 노드
    * 컨테이너를 실행하는 도커와 같은 런타임
    * API 서버와 통신하고 노드의 컨테이너를 관리하는 Kubelet
    * 애플리케이션 구성 요소 간에 네트워크 트래픽을 로드밸런싱하는 kube-proxy
* 쿠버네티스에서 애플리케이션 실행
  * 애플리케이션 컨테이너 이미지화 -> 레지스트리로 이미지 푸시 -> API 서버에 애플리케이션 디스크립션 게시
  * 디스크립션으로 컨테이너를 실행하는 방법
    * 스케줄러가 각 컨테이너에 필요한 리소스 계산 후 적절한 워커 노드에 할당
    * 워커 노드의 Kubelet이 레지스트리에서 이미지 받아 실행
  * 실행된 컨테이너 유지
    * 배포 상태가 디스크립션과 같은지 확인 후 다를 경우 일치하도록 일치하도록 인스턴스 재 실행
    * 워커 노드에 장애 시 해당 노드에 실행되는 컨테이너 전체 재 스케줄링
  * 복제본 수 스케일링
    * 애플리케이션 실행 도중 복제본 수 조정 가능
    * 리소스, 부하 등 여러 기준을 통해 자동으로 조정 가능
  * 이동한 애플리케이션에 접근
    * 특정 서비스를 하는 컨테이너들을 쿠버네티스는 하나의 고정 IP로 이를 사용자에게 노출시켜줌
    * 컨테이너가 재 스케줄링 되어 새로운 노드에서 실행되더라도 서비스의 IP는 변하지 않음
    * kube-proxy가 같은 서비스의 컨테이너간 로드밸런싱 담당
  * 쿠버네티스 사용의 장점
    * 운영 팀이 애플리케이션 배포 처리할 필요 없어짐
  * 애플리케이션 배포의 단순화
    * 워커 노드들이 하나의 컴퓨팅 리소스로 자동 관리되기에, 특정 조건을 가진 노드에서 실행하기 위해 시스템 관리자가 개입할 필요가 없어짐
    * 따라서 개발자들이 특정 리소스를 사용하기 위해 시스템에 대해 알 필요가 없어짐
  * 하드웨어 활용도
    * 쿠버네티스가 애플리케이션에 적합한 노드를 자동으로 찾아주기에, 한 노드에서 최적의 애플리케이션 배치를 실행
    * 스케줄링은 언제든지 다시 진행되기에 항상 최적의 상태를 유지
  * 상태 확인과 자가치유
    * 워커 노드 장애시 자동으로 해당 노드의 컨테이너들을 타 노드로 스케줄링
    * 따라서 운영 팀은 장애 대응시 해당 노드의 회복에만 집중 가능
  * 오토스케일링
    * 부하 급증에 대한 지속적인 모니터링에 인력이 투입될 필요가 없어짐
    * 클라우드 제공업체의 API로 쉽게 스케일 아웃 가능
  * 애플리케이션 개발 단순화
    * 개발과 프로덕션 환경의 동일화
    * 서비스 디스커버리와 같은 인프라 관련 기술 개발 불필요
    * 새 버전 출시 시 오류 자동 감지 및 롤아웃
